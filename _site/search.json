[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Data Analyst | Marketing Analytics Professional"
  },
  {
    "objectID": "about.html#professional-journey",
    "href": "about.html#professional-journey",
    "title": "About Me",
    "section": "Professional Journey",
    "text": "Professional Journey\nMy inspiration for pursuing Analytics stemmed from my previous role as a Media Planner, I had opportunity with our Marketing Science team to work on a geo-lift experiment for a client and I was able to analyze the historical data and identify the control cities as well as test group and once the experiment was successful, I was given the opportunity to present and that moment made me realize this comes naturally to me and I want to pursue this. I was promoted to Media Planning Manager and requested to have analytic responsibilities as well. From there on, I felt the industry was constantly evolving and I need to keep up with it so I decided to pursue Masters in Business Analytics at Boston University.\nAfter completing the course, I feel like I have a better understanding of the full marketing execution workflow all the way upto analysis of campaign performance and reporting. Most importantly I am not afraid to challenge myself to learn new tools and techniques that can be used in Marketing Measurement frameworks. I have also had opportunity to work hands-on with healthcare data and there I am most interested in analyzing patient data for resource allocation, identifying trends/patterns of symptoms for a particular disease and even claims data to recommend ways of streamlining the process more efficiently. Over the period of last 1.5 years I have worked with classmates, teammembers on hackathons, professors on exploring advanced topics while preparing for job applications and what I have realized is that I have developed a practice of using AI to execute my logic and completely depend on my learning and understanding for figuring out how to solve business problems by using the data at hand. I have been constantly practicing converting business problems into analytic questions for the data so my query and code writing becomes easy.\nApart from practicing proficiency in usual analytical tools and techniques like Python, R, SQL and BI platforms like Power BI, Excel and Tableau, I am willing to learn tools that an organization requires, document processes and constantly work on improving my ability to communicate learnings from the data analysis in the most simple way so that coming to conclusions & business decisions is easier for stakeholders and decision makers."
  },
  {
    "objectID": "about.html#skills-expertise",
    "href": "about.html#skills-expertise",
    "title": "About Me",
    "section": "Skills & Expertise",
    "text": "Skills & Expertise\n\nTechnical Skills\n\nProgramming: Python, R\nDatabase: MySQL, PostgreSQL\nData Visualization: Tableau, Power BI, Excel, Datorama\nMachine Learning: Scikit-learn, Predictive Modeling, Regression algorithms, Forecasting models, Classification algorithms and Forecasting models\nCloud systems: Git, AWS, Spark (SparkSQL, PySpark)\nStatistics: Hypothesis testing, Chi-square test, T-tests, probability distributions\nMarketing Analytics: GA4 (Google Analytics), A/B testing, Media Mix Modeling (MMM), Market Research, Audience segmentation, Google Tag Manager (GTM), paid media strategy, Marketing measurement frameworks.\n\n\n\nDomain Expertise\n\nMarketing Analytics\nHealthcare Analytics\n\nBusiness Intelligence\nData Storytelling"
  },
  {
    "objectID": "about.html#education-certifications",
    "href": "about.html#education-certifications",
    "title": "About Me",
    "section": "Education & Certifications",
    "text": "Education & Certifications\n\nMasters of Science in Business Analytics - Boston University (2025)\nPostgraduate certificate in Brand Management - Seneca College of Arts & Science (2022)\nGoogle Data Analytics Professional Certificate - Google (2023)\nAWS Cloud Practitioner - Amazon Web Services (2025)\nMeta Certified Marketing Science Professional - Meta Blueprint (2025) Ongoing"
  },
  {
    "objectID": "about.html#currently-learning",
    "href": "about.html#currently-learning",
    "title": "About Me",
    "section": "Currently Learning",
    "text": "Currently Learning\n\nAdvanced Regression algorithms for Marketing Analytics.\nCore basics of Marketing Mix Modeling.\nAttribution and Incrementality testing & how to built these measurmenet frameworks for Marketing Analytics.\nUnderstanding pipelines and their design principles so I can make life easy for Marketing reporting teams.\n\n\n“Marketing without data analysis & research for a brand is like hoping to drive business results by random trials & opinions”"
  },
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Professional Resume",
    "section": "",
    "text": "Now the headings are in Quarto markdown (not inside HTML blocks), so the TOC should work properly while still maintaining all your styling!"
  },
  {
    "objectID": "resume.html#professional-summary",
    "href": "resume.html#professional-summary",
    "title": "Professional Resume",
    "section": "Professional Summary",
    "text": "Professional Summary\n\nPaid media planner and analyst with over 2 years of experience in planning omni-channel media plans for clients across automotive, entertainment and insurance verticals. I have closely worked with Marketing Science team to establish my foundation in Marketing Analytics and had hands-on experience in designing experiments to report on incremental metrics for digital campaigns. My biggest achievement in my previous role was identifying audience segments for an automotive clients campaign using historical data and 3rd party audience data and then test it on new platforms & combining with influencer marketing to create a wider impact. The campaign was awarded Twitch campaign of the year for esports category in 2022 and I had the opportunity to present the case study.\nMore recently I am working as Data Analyst at a non-profit and using data from various government sources to empower their event planning and fundraising strategy using tools like SQL, Python and Power BI."
  },
  {
    "objectID": "resume.html#work-experience",
    "href": "resume.html#work-experience",
    "title": "Professional Resume",
    "section": "Work Experience",
    "text": "Work Experience\n\nData Analyst\nPropa City Community Outreach\nJune 2025 - Present\n\nEngineered a PostgreSQL relational database to centralize 1,500+ programs and resources records, reducing query times by 40% and improving data accessibility for monthly board reviews.\nAutomated Salesforce-to-database data ingestion using a Python ETL pipeline, reducing manual data collection and transfer time by 70%\nDeveloped a Power BI dashboard tracking annual events and maternal health program KPIs, enabling comprehensive reporting to board members and reallocation of $50K funding to workshops.\nPresented data-driven outreach insights during the Massachusetts PPD initiative, resulting in partnerships with 2 medical centres serving 3 neighborhoods.\n\n\n\nMedia Planning Manager\nOmnicom Media Group\nOct 2023 - Aug 2024\n\nDirected omni-channel planning for Cineplex Pan Canada using marketing mix modeling results, achieving a 20% YoY reach increase by reallocating 30% of Facebook budget to TikTok and CTV based on performance data\nLed annual media planning for Cineplex’s Playdium and Recroom brand portfolios of $3M, using Data Management Platforms (DMPs) audience segments as well as Adobe 1P data to shift 100% of TV budget to Programmatic CTV, increasing YoY reach by 20%\nOptimized Porsche’s Digital Plan by analyzing GA4 cross-channel attribution (paid social v/s display), reallocating 15% of Meta spend to high performing Twitch and Pinterest placements and combining it with Influencer boosted plan, winning ‘Twitch Esports Campaign of the year 2022.’\nCollaborated with Marketing science team to build a Datorama dashboard tracking cross-channel performance (paid social, search, programmatic, CTV & OOH), integrated platform-specific metrics (Facebook CPM, YouTube CPV) into a unified view, enabling weekly recommendations and optimization reports to the client.\nLed competitive analysis using industry and audience data from Telmar, Vividata, Nielsen and Environics through Omni, identifying Share of Voice (SOV) for Porsche’s luxury auto category.\n\n\n\nMedia Planning Associate\nOmnicom Media Group\nMay 2022 - Oct 2023\n\nManaged end-to-end ad operations including campaign trafficking sheets, tag QA, and insertion orders across multiple channels, reducing errors by 20% through systematic process improvements and cross-checks with execution team\nAssisted in QA checks for a Tableau dashboard (validating GA4 metrics vs. platform data) ensuring accuracy for bi-weekly client reporting presentations.\nPartnered with Digital execution team to leverage Lotame and Nielsen audiences under Omni for refining Ferrero’s ecommerce campaigns, improving ROAS by 3.5x than the traditional search plan.\nPulled and compiled weekly platform reports (Google Ads, DV360, Meta Ads Manager) for senior planners, flagging underperforming campaigns for optimization."
  },
  {
    "objectID": "resume.html#education",
    "href": "resume.html#education",
    "title": "Professional Resume",
    "section": "Education",
    "text": "Education\n\nMaster of Science in Applied Business Analytics\nBoston University\nExpected: May 2025 | GPA: 3.8/4.0\nRelevant Coursework: Data Mining, Big Data Analytics, Machine Learning, Data Visualization, Statistical Methods\n\n\nPost-graduate Certificate Diploma\nSeneca College of Arts & Science\nGraduated: April 2022 | GPA: 3.8/4.0\nRelevant Coursework: Case tudy analysis, Media planning, Advertising strategy, Product analysis."
  },
  {
    "objectID": "resume.html#technical-skills",
    "href": "resume.html#technical-skills",
    "title": "Resume",
    "section": "",
    "text": "Programming\nPython, R, SQL, JavaScript\n\n\nData Visualization\nTableau, Power BI, Matplotlib, Plotly\n\n\nMachine Learning\nScikit-learn, TensorFlow, Predictive Modeling\n\n\nTools & Platforms\nAWS, Git, Docker, Jupyter, Excel"
  },
  {
    "objectID": "resume.html#certifications",
    "href": "resume.html#certifications",
    "title": "Resume",
    "section": "",
    "text": "Google Data Analytics Professional Certificate - Google (2023)\nAWS Certified Cloud Practitioner - Amazon Web Services (2022)\nTableau Desktop Specialist - Tableau (2022)\n\n–"
  },
  {
    "objectID": "resume.html#projects",
    "href": "resume.html#projects",
    "title": "Resume",
    "section": "",
    "text": "Customer Segmentation Analysis: Clustered 50K+ customers using K-means\nSales Forecasting Model: Achieved 94% accuracy in quarterly predictions\nReal-time Dashboard: Built interactive dashboard monitoring key metrics"
  },
  {
    "objectID": "test-about.html",
    "href": "test-about.html",
    "title": "Test About",
    "section": "",
    "text": "Image Test\n\n\n\nIf you see a blue circle, the image loaded. If you see broken image icon, the URL is wrong."
  },
  {
    "objectID": "about.html#professional-journey-professional-journey-.content-section",
    "href": "about.html#professional-journey-professional-journey-.content-section",
    "title": "About Me",
    "section": "Professional Journey {#professional-journey .content-section",
    "text": "Professional Journey {#professional-journey .content-section\n[Your professional story here…]\nStarted my journey in data analytics when… Currently focused on… Passionate about…"
  },
  {
    "objectID": "about.html#skills-expertise-skills-expertise",
    "href": "about.html#skills-expertise-skills-expertise",
    "title": "About Me",
    "section": "Skills & Expertise {#skills-expertise",
    "text": "Skills & Expertise {#skills-expertise\n\nTechnical Skills\n\nProgramming: Python, R\nDatabase: MySQL, PostgreSQL\nData Visualization: Tableau, Power BI, Excel, Datorama\nMachine Learning: Scikit-learn, Predictive Modeling, Regression algorithms, Forecasting models, Classification algorithms and Forecasting models\nCloud systems: Git, AWS, Spark (SparkSQL, PySpark)\nStatistics: Hypothesis testing, Chi-square test, T-tests, probability distributions\nMarketing Analytics: GA4 (Google Analytics), A/B testing, Media Mix Modeling (MMM), Market Research, Audience segmentation, Google Tag Manager (GTM), paid media strategy, Marketing measurement frameworks.\n\n\n\nDomain Expertise\n\nMarketing Analytics\nHealthcare Analytics\n\nBusiness Intelligence\nData Storytelling"
  },
  {
    "objectID": "about.html#education-certifications-education-certifications-n",
    "href": "about.html#education-certifications-education-certifications-n",
    "title": "About Me",
    "section": "Education & Certifications {#education-certifications n}",
    "text": "Education & Certifications {#education-certifications n}\n\nBachelor of Science in Data Science - University Name (Year)\nGoogle Data Analytics Professional Certificate - Google (Year)\nAWS Cloud Practitioner - Amazon Web Services (Year)"
  },
  {
    "objectID": "about.html#skills",
    "href": "about.html#skills",
    "title": "About Me",
    "section": "Skills",
    "text": "Skills\n\nTechnical Skills\n\nProgramming: Python, R\nDatabase: MySQL, PostgreSQL\nData Visualization: Tableau, Power BI, Excel, Datorama\nMachine Learning: Scikit-learn, Predictive Modeling, Regression algorithms, Forecasting models, Classification algorithms and Forecasting models\nCloud systems: Git, AWS, Spark (SparkSQL, PySpark)\nStatistics: Hypothesis testing, Chi-square test, T-tests, probability distributions\nMarketing Analytics: GA4 (Google Analytics), A/B testing, Media Mix Modeling (MMM), Market Research, Audience segmentation, Google Tag Manager (GTM), paid media strategy, Marketing measurement frameworks.\n\n###Domain Expertise - Marketing Analytics - Healthcare Analytics\n- Business Intelligence - Data Storytelling\n##Education & Certifications {#education-certifications}\n\nBachelor of Science in Data Science - University Name (Year)\nGoogle Data Analytics Professional Certificate - Google (Year)\nAWS Cloud Practitioner - Amazon Web Services (Year)\n\n##Currently Learning {#currently-learning}\n\nAdvanced Machine Learning techniques\nCloud data engineering\nReal-time analytics platforms\n\n\n“Your favorite data-related quote or personal philosophy”"
  },
  {
    "objectID": "contact.html",
    "href": "contact.html",
    "title": "Contact form",
    "section": "",
    "text": "CONTACT ME\n\n\n\n  \n      \n      \n        \n          First Name\n          \n        \n        \n          Last Name\n          \n        \n      \n      \n      \n        Email\n        \n      \n      \n      \n        Type your message here...\n        \n      \n      \n      Submit\n    \n    \n  \n  \n  \n  \n    \n      Hiten Ladkani\n      Data Analyst | Marketing Analytics Professional\n    \n    \n    \n      \n        \n          \n        \n        Email\n      \n      \n      \n        \n          \n        \n        LinkedIn\n      \n      \n      \n        \n          \n        \n        GitHub"
  },
  {
    "objectID": "resume.html#technical-tools-stack",
    "href": "resume.html#technical-tools-stack",
    "title": "Professional Resume",
    "section": "Technical Tools Stack",
    "text": "Technical Tools Stack\n\n  \n    \n    Python\n  \n  \n    \n    SQL\n  \n  \n    \n    PostgreSQL\n  \n  \n    \n    R\n  \n  \n    \n    Apache Spark\n  \n  \n    \n    AWS EC2\n  \n  \n    \n    AWS S3\n  \n  \n    \n    VS Code\n  \n  \n    \n    Jupyter\n  \n  \n    \n    Google Colab\n  \n  \n    \n    GitHub\n  \n  \n    \n    Excel\n  \n  \n    \n    Power BI\n  \n  \n    \n    Tableau\n  \n  \n    \n    Looker Studio\n  \n  \n    \n    Google Analytics\n  \n  \n    \n    Quarto"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Data Analytics Projects",
    "section": "",
    "text": "Ecommerce Sales Attribution and Marketing Segmentation\n\n  \n    \n      \n        \n      \n      \n        \n          Ecommerce Sales Attribution and Marketing Segmentation\n        \n        \n          Analyzing customer purchase patterns via an RFM model and marketing channel effectiveness to optimize sales attribution and create targeted customer segments for personalized marketing campaigns.\n        \n        \n          \n             GitHub\n          \n          \n             Tableau\n          \n        \n      \n    \n  \n\n  \n    \n      \n      \n        \n          Project Scenario\n        \n        \n          \n            Context and Overview\n            As a junior marketing data analyst for an e-commerce brand running on Shopify, my job is to analyze purchase and campaign data to identify what channels are driving most revenue, how different are purchase behaviors of various customer segments and if there are any untapped opportunities as well as how the business can improve further. \n            \n            Key Objectives\n            \n              Analyze sales performance metrics by channel for future budget allocation\n              Identify customer segment profiles and analyze their purchase patterns\n              Provide actionable recommendations for marketing channel mix and KPI improvements\n            \n          \n        \n      \n\n      \n      \n        \n          Business Problem and Stakeholders Questions\n        \n        \n          \n            Business Challenge\n            How can we clearly quantify each marketing channel impact on business outcomes and surface various customer segments for the brand by leveraging the Shopify transaction data as well as campaign data to optimize the marketing spend and personalize communication strategy for each customer segment? \n            \n            Stakeholder Questions\n            \n              E-commerce Manager: Needs clear performance metrics by each channel to formulate future budget allocation.\n              Marketing Lead: Seeks insight into attribution models (first-touch, last-touch and multi-touch) to optimize campaigns and channel mix.\n              Merchandising Team: Wants clearly identified customer segment profiles to tailor site content and promotions.\n            \n            \n            \n            Visual representation of the business problem\n          \n        \n      \n\n      \n      \n        \n          Data Requirements & Gathering\n        \n        \n          \n            Data Sources\n            \n              Orders table: This is the source table, and the table includes digital purchase transactions data. What was bought, when and how much. \n              DimAttribution: This is the dimension table which includes data on the traffic source in terms of marketing channel and which device the session was logged in\n              DimCustomer: Another dimension table that contains customer information. The orders table is the source of truth in this analysis, and the dimension tables will be joined to the source table to create our analytical base which will be the prep table.\n            \n            \n            Data Transformation & Consolidation\n            Prep Table - This table is prepared by using the RIGHT JOIN with the Orders table on the two dimension tables using order number as the reference key. \n            This provides attribution and customer information for each order number in the Orders table and those that have missing information are excluded. A quick data validation check is done to ensure that the prep table rows does not exceed order table rows in case of the RIGHT JOIN and in LEFT JOIN the row numbers should be equal.\n          \n        \n      \n\n      \n      \n        \n          Data Cleaning & Transformation\n        \n        \n          \n            Exploring distribution of key metrics and scope of data (Exploratory Data Analysis)\n             i. Summary statistics of Order & refund amounts:The order amounts distribution heavy right tail and most orders clustered on the left with higher skew on the left side because of refunded orders. At initial stage this suggests high number of one-time purchasers.\n            \n            \n            Summary statistics  \n\n             The refund amounts in the dataset is only 2, which reduces the scope of the analysis as we need not analyze these refund amounts since these numbers are expected in digital transactions.\n\n            \n            Summary statistics \n\n             ii. Scope of dataset and volume of orders by month:The data ranges from March 13th 2024 to 22nd July 2025, just over an year worth of data. \n\n            \n            Dataset scope \n\n            \n            Monthly orders \n\n            As typically observed in retail sales, correction happens after initial burst of sales after opening (assuming the brand opened its online store since March 2024) which has happened in this case as the sales in the 1st quarter of 2025 dropped to some extent. \n\n             iii. Analyzing distribution of key metrics:\n\n            \n            Order status distribution \n\n            Orders that have pending payment will be excluded from revenue and other analysis, so the results are not inflated. \n\n            \n            Payment methods distribution \n\n            Most of the transactions have been completed through card and some of these categories can be collapsed into one to streamline analysis.\n            \n            \n            Orders by countries \n\n            Similar to the trend in order amounts, majority of the transactions have come from 7-8 countries and the distribution is similar with heavy right tail.  \n\n            \n            Attribution Channels\n\n             Similar to payment methods, there are similar categories of channels which can be collapsed into one.\n\n            \n            Attribution Devices\n            \n             Desktop and mobile are the only two sources for this data and the duplicates need to be removed and combined into one. \n\n             iv. Data Cleaning and Fixing fields:Fixing Attribution Sources and Devices to create clean columns\n            \n            \n            Attribution Channels\n          \n        \n      \n\n      \n      \n        \n          Data Analysis\n        \n        \n          \n            Shaping Data and Analysis\n            Shaping Data and analysis:.\n            This is a critical stage where cleaned data is being transformed into analysis-ready views. This profiling will enable implementation of RFM segmentation of customers and cohort analysis to understand customer behavior, long-term value and loyalty for the business.\n\n            i. Revenue by Channel and Lifetime Value of customers:Order_count and Average Order value are also calculated for orders attributed to each channel to give a complete picture of contribution of a marketing channel\n\n            \n            Revenue and AOV\n            \n            \n            LTV by customer\n\n            Life span days for each customer are calculated based on their purchase data, LTV calculation in this case is useless as most of the customers are one-time buyers till date.\n\n          \n        \n      \n\n      \n      \n        \n          Dashboard Presentation\n        \n        \n          \n            \n              \n              Dashboard/Video Presentation will be embedded here\n            \n          \n        \n      \n    \n  \n\n\n\nA/B Testing of Advertising Campaign Results\n\n  \n    \n      \n        \n      \n      \n        \n          A/B Testing of Advertising Campaign Results\n        \n        \n          Designing and analyzing A/B tests for advertising campaigns to measure effectiveness, optimize ad spend, and identify the most impactful creative and targeting strategies.\n        \n        \n          \n             GitHub\n          \n          \n             Tableau\n          \n        \n      \n    \n  \n\n  \n    \n      \n        \n          Business Problem and Stakeholders Questions\n        \n        \n          \n            Content about business problem and stakeholder questions will go here...\n          \n        \n      \n\n      \n        \n          Data Requirements & Gathering\n        \n        \n          \n            Content about data requirements and gathering process will go here...\n          \n        \n      \n\n      \n        \n          Data Analysis\n        \n        \n          \n            Content about data analysis methodology and findings will go here...\n          \n        \n      \n\n      \n        \n          Presentation\n        \n        \n          \n            \n              \n              Dashboard/Video Presentation will be embedded here\n            \n          \n        \n      \n    \n  \n\n\n\nNHL Player Salary Prediction Analysis\n\n  \n    \n      \n        \n      \n      \n        \n          NHL Player Salary Prediction Analysis\n        \n        \n          Building predictive models to forecast NHL player salaries based on performance metrics, team statistics, and market factors to support contract negotiations and team budgeting.\n        \n        \n          \n             GitHub\n          \n          \n             Looker Studio\n          \n        \n      \n    \n  \n\n  \n    \n      \n        \n          Business Problem and Stakeholders Questions\n        \n        \n          \n            Content about business problem and stakeholder questions will go here...\n          \n        \n      \n\n      \n        \n          Data Requirements & Gathering\n        \n        \n          \n            Content about data requirements and gathering process will go here...\n          \n        \n      \n\n      \n        \n          Data Analysis\n        \n        \n          \n            Content about data analysis methodology and findings will go here...\n          \n        \n      \n\n      \n        \n          Presentation\n        \n        \n          \n            \n              \n              Dashboard/Video Presentation will be embedded here\n            \n          \n        \n      \n    \n  \n\n\n\nCovid-19 Testing Capacity and Resource Allocation Analysis\n\n  \n    \n      \n        \n      \n      \n        \n          Covid-19 Testing Capacity and Resource Allocation Analysis\n        \n        \n          Analyzing testing capacity data and resource allocation patterns to optimize public health response and ensure efficient distribution of testing resources during the pandemic.\n        \n        \n          \n             GitHub\n          \n          \n             Power BI\n          \n        \n      \n    \n  \n\n  \n    \n      \n        \n          Business Problem and Stakeholders Questions\n        \n        \n          \n            Content about business problem and stakeholder questions will go here...\n          \n        \n      \n\n      \n        \n          Data Requirements & Gathering\n        \n        \n          \n            Content about data requirements and gathering process will go here...\n          \n        \n      \n\n      \n        \n          Data Analysis\n        \n        \n          \n            Content about data analysis methodology and findings will go here...\n          \n        \n      \n\n      \n        \n          Presentation\n        \n        \n          \n            \n              \n              Dashboard/Video Presentation will be embedded here"
  }
]